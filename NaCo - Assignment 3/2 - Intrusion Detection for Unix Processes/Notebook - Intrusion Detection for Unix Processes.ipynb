{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28850ef4fcf5c893",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Intrusion Detection for Unix Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f8772fbd89d9897",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:21:30.060056700Z",
     "start_time": "2024-02-25T01:21:30.016757900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28a677a6d0bac385",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:38:02.619240900Z",
     "start_time": "2024-02-25T01:38:02.596796900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the chunk length\n",
    "chunk_length = 7\n",
    "\n",
    "directory_path = 'syscalls/'\n",
    "\n",
    "# File paths for snd-cert\n",
    "snd_cert_train_file_path = os.path.join(directory_path, 'snd-cert/train/snd-cert.train')\n",
    "snd_cert_test_file_paths = [os.path.join(directory_path, f'snd-cert/tests/snd-cert.{i}.test') for i in range(1, 4)]\n",
    "snd_cert_label_file_paths = [os.path.join(directory_path, f'snd-cert/labels/snd-cert.{i}.labels') for i in range(1, 4)]\n",
    "snd_cert_alpha_file_path = os.path.join(directory_path, 'snd-cert/alphabet/snd-cert.alpha')\n",
    "\n",
    "# File paths for snd-unm\n",
    "snd_unm_train_file_path = os.path.join(directory_path, 'snd-unm/train/snd-unm.train')\n",
    "snd_unm_test_file_paths = [os.path.join(directory_path, f'snd-unm/tests/snd-unm.{i}.test') for i in range(1, 4)]\n",
    "snd_unm_label_file_paths = [os.path.join(directory_path, f'snd-unm/labels/snd-unm.{i}.labels') for i in range(1, 4)]\n",
    "snd_unm_alpha_file_path = os.path.join(directory_path, 'snd-unm/alphabet/snd-unm.alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1c5586bc2af800a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:38:04.049127800Z",
     "start_time": "2024-02-25T01:38:04.023838200Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sequence(sequence, \n",
    "                        chunk_length, \n",
    "                        overlap=True):\n",
    "    \"\"\"\n",
    "    Preprocesses a given sequence into fixed-length chunks.\n",
    "    \n",
    "    This function splits a sequence into substrings of a specified fixed length. It supports both overlapping\n",
    "    and non-overlapping chunking methods. Overlapping chunks (substrings) are generated by moving one character\n",
    "    at a time, while non-overlapping chunks are generated by moving the entire length of the chunk each time.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence (str): The input sequence to be chunked.\n",
    "    - chunk_length (int): The length of each chunk (substring) to be generated.\n",
    "    - overlap (bool): Determines the chunking method. If True, overlapping chunks are created. If False,\n",
    "                      non-overlapping chunks are generated.\n",
    "    \n",
    "    Returns:\n",
    "    - chunks (list of str): A list of substrings (chunks) of the input sequence. If the input sequence is shorter\n",
    "                            than the specified chunk length and cannot be chunked, an empty list is returned.\n",
    "    \n",
    "    Note:\n",
    "    - The function strips trailing newlines and spaces from the input sequence before chunking.\n",
    "    - If 'overlap' is True, each chunk will be shifted by one character from the previous chunk, leading to\n",
    "      a higher number of generated chunks, each sharing a part with its neighbors.\n",
    "    - If 'overlap' is False, each chunk starts right after the previous one ends, with no shared characters\n",
    "      between consecutive chunks, leading to a lower number of generated chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the sequence length is at least as long as the chunk length\n",
    "    if len(sequence) < chunk_length:\n",
    "        # If the sequence is shorter than the chunk length, return an empty list or handle accordingly\n",
    "        return []\n",
    "\n",
    "    # Initialize an empty list to store the chunks\n",
    "    chunks = []\n",
    "\n",
    "    # Remove any trailing newline or spaces from the sequence\n",
    "    # sequence = sequence.strip()\n",
    "    # Determine the step size based on whether overlapping chunks are desired\n",
    "    step = 1 if overlap else chunk_length\n",
    "    # Generate and append chunks to the list\n",
    "    for i in range(0, len(sequence) - chunk_length + 1, step):\n",
    "        chunk = sequence[i:i + chunk_length]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "750498007223d609",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:38:05.727601900Z",
     "start_time": "2024-02-25T01:38:05.400126800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SND-CERT first 5 train chunks:\n",
      "Chunk 1: AEEEEEE\n",
      "Chunk 2: DBccD=c\n",
      "Chunk 3: EOVDPcE\n",
      "Chunk 4: DBccEDB\n",
      "Chunk 5: ccEEhEE\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "SND-UNM first 5 train chunks:\n",
      "Chunk 1: pooqpoo\n",
      "Chunk 2: qpooqED\n",
      "Chunk 3: EESSprs\n",
      "Chunk 4: NNpooqd\n",
      "Chunk 5: spooqdN\n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess the .train file first for snd-cert and snd-unm\n",
    "with open(snd_cert_train_file_path, 'r') as file:\n",
    "    snd_cert_train_sequences = file.readlines()\n",
    "\n",
    "with open(snd_unm_train_file_path, 'r') as file:\n",
    "    snd_unm_train_sequences = file.readlines()\n",
    "\n",
    "# Define paths for output files\n",
    "snd_cert_train_chunks_file = os.path.join(directory_path, 'snd-cert/train/snd_cert_train_chunks.train')\n",
    "snd_unm_train_chunks_file = os.path.join(directory_path, 'snd-unm/train/snd_unm_train_chunks.train')\n",
    "\n",
    "# Preprocess train sequences for snd-cert and save to file\n",
    "with open(snd_cert_train_chunks_file, 'w') as output_file:\n",
    "    snd_cert_train_chunks = []\n",
    "    for sequence in snd_cert_train_sequences:\n",
    "        # Call the preprocess function for each sequence\n",
    "        chunks = preprocess_sequence(sequence, chunk_length, overlap=False)\n",
    "        snd_cert_train_chunks.extend(chunks)\n",
    "        # Write each chunk to the file\n",
    "        for chunk in chunks:\n",
    "            output_file.write(chunk + '\\n')\n",
    "\n",
    "# Preprocess train sequences for snd-unm and save to a file\n",
    "with open(snd_unm_train_chunks_file, 'w') as output_file:\n",
    "    snd_unm_train_chunks = []\n",
    "    for sequence in snd_unm_train_sequences:\n",
    "        # Call the preprocess function for each sequence\n",
    "        chunks = preprocess_sequence(sequence, chunk_length, overlap=False)\n",
    "        snd_unm_train_chunks.extend(chunks)\n",
    "        # Write each chunk to the file\n",
    "        for chunk in chunks:\n",
    "            output_file.write(chunk + '\\n')\n",
    "\n",
    "# Print the first 5 sequences to check\n",
    "print(\"SND-CERT first 5 train chunks:\")\n",
    "for i, chunk in enumerate(snd_cert_train_chunks[:5], start=1):\n",
    "    print(f\"Chunk {i}: {chunk}\")\n",
    "\n",
    "# Print the first 5 sequences to check\n",
    "print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "print(\"SND-UNM first 5 train chunks:\")\n",
    "for i, chunk in enumerate(snd_unm_train_chunks[:5], start=1):\n",
    "    print(f\"Chunk {i}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d297502882bdce4d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:38:06.493731800Z",
     "start_time": "2024-02-25T01:38:06.461643200Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_chunks_with_identifiers(test_file_path, \n",
    "                                 chunk_length, \n",
    "                                 overlap=True,\n",
    "                                 output_chunk_file_path=None, \n",
    "                                 output_identifier_file_path=None):\n",
    "    \"\"\"\n",
    "    Splits test sequences into fixed-length chunks and assigns identifiers to track which chunks belong to the same original sequence.\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple of (chunks, identifiers) where 'chunks' is a list of the sequence chunks and 'identifiers' is a list of corresponding sequence identifiers.\n",
    "    \"\"\"\n",
    "    # Read test sequences from file\n",
    "    with open(test_file_path, 'r') as file:\n",
    "        test_sequences = file.read().splitlines()\n",
    "\n",
    "    # Initialize lists for chunks and their identifiers\n",
    "    chunks = []\n",
    "    identifiers = []\n",
    "\n",
    "    # Process each sequence to generate chunks and assign an identifier to each chunk\n",
    "    for sequence_id, sequence in enumerate(test_sequences):\n",
    "        sequence_chunks = preprocess_sequence(sequence, chunk_length, overlap)\n",
    "        chunks.extend(sequence_chunks)\n",
    "        identifiers.extend([sequence_id] * len(sequence_chunks))  # Assign the sequence ID to all of its chunks\n",
    "\n",
    "    # Save chunks and their identifiers to specified output files\n",
    "    if output_chunk_file_path and output_identifier_file_path:\n",
    "        with open(output_chunk_file_path, 'w') as chunk_file, open(output_identifier_file_path, 'w') as id_file:\n",
    "            for chunk, id in zip(chunks, identifiers):\n",
    "                chunk_file.write(chunk + '\\n')\n",
    "                id_file.write(str(id) + '\\n')\n",
    "\n",
    "    return chunks, identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bcb207c7f6793cb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:38:08.468538Z",
     "start_time": "2024-02-25T01:38:07.166848900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 chunks and their corresponding identifiers from SND-CERT Test Set 1:\n",
      "Chunk: srrtsuv, Identifier: 0\n",
      "Chunk: NNsrrtf, Identifier: 0\n",
      "Chunk: vsrrtfN, Identifier: 0\n",
      "Chunk: DlmEvNl, Identifier: 0\n",
      "Chunk: oW-kwEE, Identifier: 0\n"
     ]
    }
   ],
   "source": [
    "# Process and save test sequences with identifiers for both snd-cert and snd-unm datasets.\n",
    "\n",
    "# Define the output file paths for chunks and their corresponding identifiers.\n",
    "output_files_snd_cert = [\n",
    "    (os.path.join(directory_path, f'snd-cert/tests/snd_cert_test_set_{i}_chunks.test'),\n",
    "     os.path.join(directory_path, f'snd-cert/tests/snd_cert_test_set_{i}_identifiers.txt'))\n",
    "    for i in range(1, 4)]\n",
    "\n",
    "output_files_snd_unm = [\n",
    "    (os.path.join(directory_path, f'snd-unm/tests/snd_unm_test_set_{i}_chunks.test'),\n",
    "     os.path.join(directory_path, f'snd-unm/tests/snd_unm_test_set_{i}_identifiers.txt'))\n",
    "    for i in range(1, 4)]\n",
    "\n",
    "# Iterate over test and label file paths along with output file paths for snd-cert\n",
    "for (test_file, label_file), (output_chunk_file, output_label_file) in zip(\n",
    "        zip(snd_cert_test_file_paths, snd_cert_label_file_paths), output_files_snd_cert):\n",
    "    snd_cert_test_chunks, snd_cert_test_identifier = save_chunks_with_identifiers(test_file,\n",
    "                                                                                  chunk_length,\n",
    "                                                                                  overlap=False,\n",
    "                                                                                  output_chunk_file_path=output_chunk_file,\n",
    "                                                                                  output_identifier_file_path=output_label_file)\n",
    "\n",
    "# Iterate over test and label file paths along with output file paths for snd-unm\n",
    "for (test_file, label_file), (output_chunk_file, output_label_file) in zip(\n",
    "        zip(snd_unm_test_file_paths, snd_unm_label_file_paths), output_files_snd_unm):\n",
    "    snd_unm_test_chunks, snd_unm_test_identifier = save_chunks_with_identifiers(test_file,\n",
    "                                                                                chunk_length,\n",
    "                                                                                overlap=False,\n",
    "                                                                                output_chunk_file_path=output_chunk_file,\n",
    "                                                                                output_identifier_file_path=output_label_file)\n",
    "\n",
    "# Print the first 5 sequences to check\n",
    "example_chunk_file = os.path.join(directory_path, 'snd-cert/tests/snd_cert_test_set_1_chunks.test')\n",
    "example_identifier_file = os.path.join(directory_path, 'snd-cert/tests/snd_cert_test_set_1_identifiers.txt')\n",
    "\n",
    "print(\"First 5 chunks and their corresponding identifiers from SND-CERT Test Set 1:\")\n",
    "with open(example_chunk_file, 'r') as chunks_file, open(example_identifier_file, 'r') as ids_file:\n",
    "    for _ in range(5):\n",
    "        chunk = chunks_file.readline().strip()\n",
    "        identifier = ids_file.readline().strip()\n",
    "        print(f\"Chunk: {chunk}, Identifier: {identifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def get_sequences_score(file_path_scores, \n",
    "                        file_path_identifier, \n",
    "                        file_path_label):\n",
    "    \"\"\"\n",
    "    This method calculates the average anomaly score for each sequence by grouping individual chunk scores based on shared identifiers, then returns these average scores along with their corresponding sequence labels.\n",
    "    \"\"\"\n",
    "    # Read anomaly scores from the file\n",
    "    with open(file_path_scores, 'r') as file:\n",
    "        scores = [float(line.strip()) for line in file.readlines()]\n",
    "\n",
    "    # Read identifiers to group scores by originating sequence\n",
    "    with open(file_path_identifier, 'r') as file:\n",
    "        identifiers = [int(line.strip()) for line in file.readlines()]\n",
    "        # print(identifiers)\n",
    "\n",
    "    # Read labels corresponding to each sequence\n",
    "    with open(file_path_label, 'r') as file:\n",
    "        labels = [int(line.strip()) for line in file.readlines()]\n",
    "\n",
    "    # Initialize a list to hold the average score of each sequence\n",
    "    sequence_scores = []\n",
    "\n",
    "    # Initialize a list to accumulate scores for the current sequence\n",
    "    current_sequence_scores = [scores[0]]\n",
    "\n",
    "    # Loop through all scores to calculate average scores per sequence\n",
    "    for i in range(1, len(scores)):\n",
    "        # If the current score belongs to the same sequence, add it to the accumulator\n",
    "        if identifiers[i] == identifiers[i - 1]:\n",
    "            current_sequence_scores.append(scores[i])\n",
    "        else:\n",
    "            # If the current score belongs to a new sequence, calculate the average score of the previous sequence\n",
    "            sequence_scores.append(sum(current_sequence_scores) / len(current_sequence_scores))\n",
    "            # Reset the accumulator for the new sequence\n",
    "            current_sequence_scores = [scores[i]]\n",
    "\n",
    "    # Ensure the average score of the last sequence is also included\n",
    "    sequence_scores.append(sum(current_sequence_scores) / len(current_sequence_scores))\n",
    "    \n",
    "    current_sequence_scores=[scores[i]]\n",
    "    \n",
    "    # Return the list of average sequence scores and their corresponding labels\n",
    "    return sequence_scores, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T01:51:26.754853600Z",
     "start_time": "2024-02-25T01:51:26.626495200Z"
    }
   },
   "id": "24b6de71dc128621"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "- **Command structure that includes the alphabet file for the Unix process task for snd-cert**:\n",
    "    ```bash\n",
    "    java -jar negsel2.jar -alphabet snd-cert.alpha -self snd_cert_train_chunks.train -n 10 -r 4 -c -l < snd_cert_test_set_<test_no>_chunks.test >snd_cert_test_set_<test_no>_chunks_scores_r4.txt\n",
    "    ```\n",
    "- **Same for snd-unm**:\n",
    "    ```bash\n",
    "    java -jar negsel2.jar -alphabet snd-unm.alpha -self snd_unm_train_chunks.train -n 10 -r 4 -c -l < snd_unm_test_set_<test_no>_chunks.test >snd_unm_test_set_<test_no>_chunks_scores_r4.txt\n",
    "    ```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9a1016fcdcff95"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6446b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T01:51:35.949667300Z",
     "start_time": "2024-02-25T01:51:35.865298900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the scores and labels for the first test set of the snd-unm dataset\n",
    "scores_unm1, labels_unm1 = get_sequences_score(\"syscalls/snd-unm/scores/snd_unm_test_set_1_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-unm/tests/snd_unm_test_set_1_identifiers.txt\",\n",
    "                                               \"syscalls/snd-unm/labels/snd-unm.1.labels\")\n",
    "\n",
    "# Load the scores and labels for the second test set of the snd-unm dataset\n",
    "scores_unm2, labels_unm2 = get_sequences_score(\"syscalls/snd-unm/scores/snd_unm_test_set_1_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-unm/tests/snd_unm_test_set_2_identifiers.txt\",\n",
    "                                               \"syscalls/snd-unm/labels/snd-unm.2.labels\")\n",
    "\n",
    "# Load the scores and labels for the third test set of the snd-unm dataset\n",
    "scores_unm3, labels_unm3 = get_sequences_score(\"syscalls/snd-unm/scores/snd_unm_test_set_1_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-unm/tests/snd_unm_test_set_3_identifiers.txt\",\n",
    "                                               \"syscalls/snd-unm/labels/snd-unm.3.labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22e11476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T01:49:37.924962Z",
     "start_time": "2024-02-25T01:49:37.840771800Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(scores)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c5e52f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T01:49:10.740927200Z",
     "start_time": "2024-02-25T01:49:10.285117700Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[62], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#fpr, tpr, thresholds = roc_curve(labels, scores)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m auc_unm1 \u001B[38;5;241m=\u001B[39m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels_unm1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores_unm1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m auc_unm2 \u001B[38;5;241m=\u001B[39m roc_auc_score(labels_unm2, scores_unm2)\n\u001B[0;32m      4\u001B[0m auc_unm3 \u001B[38;5;241m=\u001B[39m roc_auc_score(labels_unm3, scores_unm3)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:606\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    604\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    605\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 606\u001B[0m y_score \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    609\u001B[0m     y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    610\u001B[0m ):\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;66;03m# do not support partial ROC computation for multiclass\u001B[39;00m\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m max_fpr \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    951\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    952\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    953\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    954\u001B[0m         )\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 957\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    965\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    170\u001B[0m     )\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "#fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "auc_unm1 = roc_auc_score(labels_unm1, scores_unm1)\n",
    "auc_unm2 = roc_auc_score(labels_unm2, scores_unm2)\n",
    "auc_unm3 = roc_auc_score(labels_unm3, scores_unm3)\n",
    "print(auc_unm1, auc_unm2, auc_unm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9932efaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T01:53:31.109888100Z",
     "start_time": "2024-02-25T01:53:30.943026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the scores and labels for the first test set of the snd-cert dataset\n",
    "scores_cert1, labels_cert1 = get_sequences_score(\"syscalls/snd-cert/scores/snd_cert_test_set_1_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-cert/tests/snd_cert_test_set_1_identifiers.txt\",\n",
    "                                               \"syscalls/snd-cert/labels/snd-cert.1.labels\")\n",
    "\n",
    "# Load the scores and labels for the second test set of the snd-cert dataset\n",
    "scores_cert2, labels_cert2 = get_sequences_score(\"syscalls/snd-cert/scores/snd_cert_test_set_2_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-cert/tests/snd_cert_test_set_2_identifiers.txt\",\n",
    "                                               \"syscalls/snd-cert/labels/snd-cert.2.labels\")\n",
    "\n",
    "# Load the scores and labels for the third test set of the snd-cert dataset\n",
    "scores_cert3, labels_cert3 = get_sequences_score(\"syscalls/snd-cert/scores/snd_cert_test_set_3_chunks_scores_r4.txt\",\n",
    "                                               \"syscalls/snd-cert/tests/snd_cert_test_set_3_identifiers.txt\",\n",
    "                                               \"syscalls/snd-cert/labels/snd-cert.3.labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9767f998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T01:53:33.244974100Z",
     "start_time": "2024-02-25T01:53:33.141861600Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m auc_cert1 \u001B[38;5;241m=\u001B[39m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels_cert1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores_cert1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m auc_cert2 \u001B[38;5;241m=\u001B[39m roc_auc_score(labels_cert2, scores_cert2)\n\u001B[0;32m      3\u001B[0m auc_cert3 \u001B[38;5;241m=\u001B[39m roc_auc_score(labels_cert3, scores_cert3)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:606\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    604\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    605\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 606\u001B[0m y_score \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    609\u001B[0m     y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    610\u001B[0m ):\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;66;03m# do not support partial ROC computation for multiclass\u001B[39;00m\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m max_fpr \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    951\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    952\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    953\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    954\u001B[0m         )\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 957\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    965\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    170\u001B[0m     )\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "auc_cert1 = roc_auc_score(labels_cert1, scores_cert1)\n",
    "auc_cert2 = roc_auc_score(labels_cert2, scores_cert2)\n",
    "auc_cert3 = roc_auc_score(labels_cert3, scores_cert3)\n",
    "print(auc_cert1, auc_cert2, auc_cert3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c7fb08256f2ac64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
