{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Intrusion Detection for Unix Processes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28850ef4fcf5c893"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methodology Overview\n",
    "\n",
    "The dataset comprises system call sequences for Unix processes, both normal and anomalous, which we aim to classify accurately.\n",
    "\n",
    "### Steps followed:\n",
    "\n",
    "1. **Preprocessing Sequences:**\n",
    "   The training and test sequences are processed from `.train` and `.test` files into fixed-length chunks. This is a crucial step since the Negative Selection Algorithm requires fixed-length patterns for training and classification.\n",
    "\n",
    "2. **Parameter Selection:**\n",
    "   We choose appropriate values for `n` (the length of the detectors) and `r` (the length of the contiguous chunk that must not match the self-strings). These parameters are critical for the algorithm's performance.\n",
    "\n",
    "3. **Training the Algorithm & Classification of Test Sequences:**\n",
    "   - The algorithm is trained on the preprocessed training sequences to create a set of detectors, which will help in identifying anomalies in the test sequences.\n",
    "   - The trained algorithm is applied to the preprocessed test sequences. We calculate the number of matching patterns for each chunk and merge these counts to a composite anomaly score (average?). This score will serve as the basis for classifying the sequence as normal or anomalous.\n",
    "\n",
    "4. **AUC Analysis:**\n",
    "   Finally, we perform an AUC analysis using the `.labels` files to evaluate the quality of our classification. The `.labels` files contain the actual classification of the sequences, providing us with a ground truth to measure against."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e4e7dc6da094e2b"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:08.338284300Z",
     "start_time": "2024-02-23T18:51:08.327690Z"
    }
   },
   "id": "3f8772fbd89d9897"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing sequences\n",
    "### Preprocessing Train and Test Sequences\n",
    "The first step in our intrusion detection analysis using the negative selection algorithm involves preprocessing the raw sequences from `.train` and `.test` files. These sequences vary in length and need to be transformed into fixed-length chunks for compatibility with the negative selection algorithm. The preprocessing includes two main approaches:\n",
    "- **Sliding Window**: Chunks are created by sliding a window of the desired length across the sequence one character at a time, allowing for overlap between consecutive chunks.\n",
    "- **Non-Overlapping**: Chunks are created by dividing the sequence into contiguous segments of the desired length without any overlap between them.\n",
    "\n",
    "Each approach is chosen based on the nature of the data and the desired sensitivity of the detection algorithm. The processed training data for both the `snd-cert` and `snd-unm` datasets are stored in respective `.train` files post preprocessing. \n",
    "\n",
    "\n",
    "### Test Dataset Chunking and Labeling\n",
    "The test datasets are similarly processed into fixed-length chunks, with two main files resulting from this step:\n",
    "- **Chunk Test Files**: Each test sequence is divided into chunks using the desired approach (overlapping or non-overlapping), and these chunks are stored in `.test` files. There are three separate chunk files for each of the three test sets, corresponding to the `snd-cert` and `snd-unm` datasets.\n",
    "- **Label Files**: For each chunk created from the test sequences, a corresponding label indicating normal (0) or anomalous (1) behavior is assigned. These labels are stored in `.labels` files, with a separate label file for each of the three test sets for both `snd-cert` and `snd-unm`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f902dc01b30a979"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# Define the chunk length\n",
    "chunk_length = 7\n",
    "\n",
    "directory_path = 'syscalls/'\n",
    "\n",
    "# File paths for snd-cert\n",
    "snd_cert_train_file_path = os.path.join(directory_path, 'snd-cert/snd-cert.train')\n",
    "snd_cert_test_file_paths = [os.path.join(directory_path, f'snd-cert/snd-cert.{i}.test') for i in range(1, 4)]\n",
    "snd_cert_label_file_paths = [os.path.join(directory_path, f'snd-cert/snd-cert.{i}.labels') for i in range(1, 4)]\n",
    "snd_cert_alpha_file_path = os.path.join(directory_path, 'snd-cert/snd-cert.alpha')\n",
    "\n",
    "# File paths for snd-unm\n",
    "snd_unm_train_file_path = os.path.join(directory_path, 'snd-unm/snd-unm.train')\n",
    "snd_unm_test_file_paths = [os.path.join(directory_path, f'snd-unm/snd-unm.{i}.test') for i in range(1, 4)]\n",
    "snd_unm_label_file_paths = [os.path.join(directory_path, f'snd-unm/snd-unm.{i}.labels') for i in range(1, 4)]\n",
    "snd_unm_alpha_file_path = os.path.join(directory_path, 'snd-unm/snd-unm.alpha')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:13.907898900Z",
     "start_time": "2024-02-23T18:51:13.862393600Z"
    }
   },
   "id": "28a677a6d0bac385"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def preprocess_sequence(sequence, chunk_length, overlap=True):\n",
    "    \"\"\"\n",
    "    Preprocesses a given sequence into fixed-length chunks.\n",
    "    \n",
    "    This function splits a sequence into substrings of a specified fixed length. It supports both overlapping\n",
    "    and non-overlapping chunking methods. Overlapping chunks (substrings) are generated by moving one character\n",
    "    at a time, while non-overlapping chunks are generated by moving the entire length of the chunk each time.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence (str): The input sequence to be chunked.\n",
    "    - chunk_length (int): The length of each chunk (substring) to be generated.\n",
    "    - overlap (bool): Determines the chunking method. If True, overlapping chunks are created. If False,\n",
    "                      non-overlapping chunks are generated.\n",
    "    \n",
    "    Returns:\n",
    "    - chunks (list of str): A list of substrings (chunks) of the input sequence. If the input sequence is shorter\n",
    "                            than the specified chunk length and cannot be chunked, an empty list is returned.\n",
    "    \n",
    "    Note:\n",
    "    - The function strips trailing newlines and spaces from the input sequence before chunking.\n",
    "    - If 'overlap' is True, each chunk will be shifted by one character from the previous chunk, leading to\n",
    "      a higher number of generated chunks, each sharing a part with its neighbors.\n",
    "    - If 'overlap' is False, each chunk starts right after the previous one ends, with no shared characters\n",
    "      between consecutive chunks, leading to a lower number of generated chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the sequence length is at least as long as the chunk length\n",
    "    if len(sequence) < chunk_length:\n",
    "        # If the sequence is shorter than the chunk length, return an empty list or handle accordingly\n",
    "        return []\n",
    "\n",
    "    # Initialize an empty list to store the chunks\n",
    "    chunks = []\n",
    "\n",
    "    # Remove any trailing newline or spaces from the sequence\n",
    "    # sequence = sequence.strip()\n",
    "    # Determine the step size based on whether overlapping chunks are desired\n",
    "    step = 1 if overlap else chunk_length\n",
    "    # Generate and append chunks to the list\n",
    "    for i in range(0, len(sequence) - chunk_length + 1, step):\n",
    "        chunk = sequence[i:i + chunk_length]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:14.349497400Z",
     "start_time": "2024-02-23T18:51:14.290723200Z"
    }
   },
   "id": "e1c5586bc2af800a"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Define the function to read labels from a given file path\n",
    "def read_labels(file_path):\n",
    "    \"\"\"\n",
    "    This function reads a file with labels (one per line) and returns them as a list.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        labels = [int(line.strip()) for line in file]\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:14.905811600Z",
     "start_time": "2024-02-23T18:51:14.899814100Z"
    }
   },
   "id": "4ab42c7efb425d58"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SND-CERT first 5 train chunks:\n",
      "Chunk 1: AEEEEEE\n",
      "Chunk 2: DBccD=c\n",
      "Chunk 3: EOVDPcE\n",
      "Chunk 4: DBccEDB\n",
      "Chunk 5: ccEEhEE\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "SND-UNM first 5 train chunks:\n",
      "Chunk 1: pooqpoo\n",
      "Chunk 2: qpooqED\n",
      "Chunk 3: EESSprs\n",
      "Chunk 4: NNpooqd\n",
      "Chunk 5: spooqdN\n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess the .train file first for snd-cert and snd-unm\n",
    "with open(snd_cert_train_file_path, 'r') as file:\n",
    "    snd_cert_train_sequences = file.readlines()\n",
    "\n",
    "with open(snd_unm_train_file_path, 'r') as file:\n",
    "    snd_unm_train_sequences = file.readlines()\n",
    "\n",
    "# Define paths for output files\n",
    "snd_cert_train_chunks_file = os.path.join(directory_path, 'snd-cert/snd_cert_train_chunks.train')\n",
    "snd_unm_train_chunks_file = os.path.join(directory_path, 'snd-unm/snd_unm_train_chunks.train')\n",
    "\n",
    "# Preprocess train sequences for snd-cert and save to file\n",
    "with open(snd_cert_train_chunks_file, 'w') as output_file:\n",
    "    snd_cert_train_chunks = []\n",
    "    for sequence in snd_cert_train_sequences:\n",
    "        # Call the preprocess function for each sequence\n",
    "        chunks = preprocess_sequence(sequence, chunk_length, overlap=False)\n",
    "        snd_cert_train_chunks.extend(chunks)\n",
    "        # Write each chunk to the file\n",
    "        for chunk in chunks:\n",
    "            output_file.write(chunk + '\\n')\n",
    "\n",
    "# Print the first 5 sequences to check\n",
    "print(\"SND-CERT first 5 train chunks:\")\n",
    "for i, chunk in enumerate(snd_cert_train_chunks[:5], start=1):\n",
    "    print(f\"Chunk {i}: {chunk}\")\n",
    "\n",
    "# Preprocess train sequences for snd-unm and save to a file\n",
    "with open(snd_unm_train_chunks_file, 'w') as output_file:\n",
    "    snd_unm_train_chunks = []\n",
    "    for sequence in snd_unm_train_sequences:\n",
    "        # Call the preprocess function for each sequence\n",
    "        chunks = preprocess_sequence(sequence, chunk_length, overlap=False)\n",
    "        snd_unm_train_chunks.extend(chunks)\n",
    "        # Write each chunk to the file\n",
    "        for chunk in chunks:\n",
    "            output_file.write(chunk + '\\n')\n",
    "\n",
    "# Print the first 5 sequences to check\n",
    "print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "print(\"SND-UNM first 5 train chunks:\")\n",
    "for i, chunk in enumerate(snd_unm_train_chunks[:5], start=1):\n",
    "    print(f\"Chunk {i}: {chunk}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:15.551474900Z",
     "start_time": "2024-02-23T18:51:15.334717600Z"
    }
   },
   "id": "750498007223d609"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# Function to preprocess test sequences and assign labels, then save to files\n",
    "def preprocess_and_save_test_sequences_with_labels(test_file_path, label_file_path, chunk_length, overlap=True,\n",
    "                                                   output_chunk_file_path=None, output_label_file_path=None):\n",
    "    # Read test sequences and labels\n",
    "    with open(test_file_path, 'r') as file:\n",
    "        test_sequences = file.read().splitlines()\n",
    "    labels = read_labels(label_file_path)\n",
    "\n",
    "    chunks = []\n",
    "    chunk_labels = []\n",
    "    for sequence, label in zip(test_sequences, labels):\n",
    "        sequence_chunks = preprocess_sequence(sequence, chunk_length, overlap)\n",
    "        chunks.extend(sequence_chunks)\n",
    "        chunk_labels.extend([label] * len(sequence_chunks))  # Assign the same label to all chunks from this sequence\n",
    "\n",
    "    # Save chunks and labels to the specified output files\n",
    "    if output_chunk_file_path and output_label_file_path:\n",
    "        with open(output_chunk_file_path, 'w') as chunk_file, open(output_label_file_path, 'w') as label_file:\n",
    "            for chunk, label in zip(chunks, chunk_labels):\n",
    "                chunk_file.write(chunk + '\\n')\n",
    "                label_file.write(str(label) + '\\n')\n",
    "\n",
    "    return chunks, chunk_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:16.329596100Z",
     "start_time": "2024-02-23T18:51:16.277599800Z"
    }
   },
   "id": "d297502882bdce4d"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 chunks and their corresponding labels from SND-CERT Test Set 1:\n",
      "Chunk: srrtsuv, Label: 0\n",
      "Chunk: NNsrrtf, Label: 0\n",
      "Chunk: vsrrtfN, Label: 0\n",
      "Chunk: DlmEvNl, Label: 0\n",
      "Chunk: oW-kwEE, Label: 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "First 5 chunks and their corresponding labels from SND-UNM Test Set 1:\n",
      "Chunk: BJLDDPM, Label: 1\n",
      "Chunk: BLsNNQQ, Label: 1\n",
      "Chunk: GEHIHDK, Label: 1\n",
      "Chunk: sNsDBEs, Label: 1\n",
      "Chunk: sVPDPg-, Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold chunks and labels for snd-cert test data\n",
    "snd_cert_test_chunks_list = []\n",
    "snd_cert_labels_list = []\n",
    "\n",
    "# Define output file paths for chunks and labels\n",
    "output_files = [\n",
    "    (os.path.join(directory_path, f'snd-cert/snd_cert_test_set_{i}_chunks.test'),\n",
    "     os.path.join(directory_path, f'snd-cert/snd_cert_test_set_{i}_labels.labels'))\n",
    "    for i in range(1, 4)]\n",
    "\n",
    "# Iterate over test and label file paths along with output file paths\n",
    "for (test_file, label_file), (output_chunk_file, output_label_file) in zip(\n",
    "        zip(snd_cert_test_file_paths, snd_cert_label_file_paths), output_files):\n",
    "    chunks, labels = preprocess_and_save_test_sequences_with_labels(test_file,\n",
    "                                                                    label_file,\n",
    "                                                                    chunk_length,\n",
    "                                                                    overlap=False,\n",
    "                                                                    output_chunk_file_path=output_chunk_file,\n",
    "                                                                    output_label_file_path=output_label_file)\n",
    "    snd_cert_test_chunks_list.append(chunks)\n",
    "    snd_cert_labels_list.append(labels)\n",
    "\n",
    "# Initialize lists to hold chunks and labels for snd-cert test data\n",
    "snd_unm_test_chunks_list = []\n",
    "snd_unm_labels_list = []\n",
    "\n",
    "# Generate output file paths dynamically\n",
    "output_files = [\n",
    "    (os.path.join(directory_path, f'snd-unm/snd_unm_test_set_{i}_chunks.test'),\n",
    "     os.path.join(directory_path, f'snd-unm/snd_unm_test_set_{i}_labels.labels'))\n",
    "    for i in range(1, 4)]\n",
    "\n",
    "# Iterate over test and label file paths along with output file paths\n",
    "for (test_file, label_file), (output_chunk_file, output_label_file) in zip(\n",
    "        zip(snd_unm_test_file_paths, snd_unm_label_file_paths), output_files):\n",
    "    chunks, labels = preprocess_and_save_test_sequences_with_labels(test_file, \n",
    "                                                                    label_file, \n",
    "                                                                    chunk_length, \n",
    "                                                                    overlap=False,\n",
    "                                                                    output_chunk_file_path=output_chunk_file,\n",
    "                                                                    output_label_file_path=output_label_file\n",
    "                                                                    )\n",
    "    snd_unm_test_chunks_list.append(chunks)\n",
    "    snd_unm_labels_list.append(labels)\n",
    "\n",
    "# View the first 5 chunks and labels from the first test set for snd-cert\n",
    "print(\"First 5 chunks and their corresponding labels from SND-CERT Test Set 1:\")\n",
    "for chunk, label in zip(snd_cert_test_chunks_list[0][:5], snd_cert_labels_list[0][:5]):\n",
    "    print(f\"Chunk: {chunk}, Label: {label}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70 + \"\\n\")\n",
    "\n",
    "# View the first 5 chunks and labels from the first test set for snd-unm\n",
    "print(\"First 5 chunks and their corresponding labels from SND-UNM Test Set 1:\")\n",
    "for chunk, label in zip(snd_unm_test_chunks_list[0][:5], snd_unm_labels_list[0][:5]):\n",
    "    print(f\"Chunk: {chunk}, Label: {label}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T18:51:18.096874400Z",
     "start_time": "2024-02-23T18:51:17.152498500Z"
    }
   },
   "id": "7bcb207c7f6793cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter Selection for Negative Selection Algorithm\n",
    "\n",
    "With the preprocessing complete, the next critical step is parameter selection for the negative selection algorithm. This involves setting the value of `n` and determining an appropriate value for `r`.\n",
    "\n",
    "- **Length of Detectors (n)**: For our analysis, we set the length of the detectors `n` equal to the length of the fixed-size chunks, which is 7 in our case. (NOT SURE)\n",
    "\n",
    "- **Contiguous Chunk Length (r)**: The value for `r` is not yet determined. (NEED TO CHECK)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dacc17bf7db47169"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Algorithm & Classification of Test Sequences\n",
    "The anomaly scores were generated using the Negative Selection ALgorithm. The scores were outputted to text files for subsequent analysis. Below are the commands used for  `r` value, structured to enhance readability:\n",
    "\n",
    "- **Command structure that includes the alphabet file for the Unix process task for snd-cert**:\n",
    "    ```bash\n",
    "    java -jar negsel2.jar -alphabet snd-cert.alpha -self snd_cert_train_chunks.train -n <chosen_n_value> -r <r_value> -c -l < snd_cert_test_set_<test_no>_chunks.test >snd_cert_test_set_<test_no>_chunks_scores_r<r_value>.txt\n",
    "    ```\n",
    "- **Same for snd-unm**:\n",
    "    ```bash\n",
    "    java -jar negsel2.jar -alphabet snd-unm.alpha -self snd_unm_train_chunks.train -n <chosen_n_value> -r <r_value> -c -l < snd_unm_test_set_<test_no>_chunks.test >snd_unm_test_set_<test_no>_chunks_scores_r<r_value>.txt\n",
    "    ```\n",
    "\n",
    "**Now, with the generated text files containing the scores for each r value and each language, we are ready to proceed with the analysis.**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6a48e055fe75700"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7420f48083ee2d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
